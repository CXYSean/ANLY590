{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNs Lab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oeTRribu75d"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as tfk\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tfkl = tfk.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv0GpRAru98a"
      },
      "source": [
        "**Preprocessing**\n",
        "\n",
        "As typical, we'll start with the MNIST data. Recall from last time, we have to do some transformations and preprocessing on these images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzZgrGQivHMh"
      },
      "source": [
        "data, info = tfds.load('mnist', with_info=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UIPvj-sFxU2"
      },
      "source": [
        "preprocess = lambda d: (tf.cast(d[\"image\"], tf.float32)/255, tf.one_hot(d[\"label\"], depth=10))\n",
        "\n",
        "ds_train = data[\"train\"].map(preprocess).cache().batch(32).prefetch(16)\n",
        "ds_test = data[\"test\"].map(preprocess).cache().batch(32).prefetch(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVxvHMXTGzXo"
      },
      "source": [
        "img_shape = info.features['image'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k9r8vw9HDNt",
        "outputId": "fc0ca0f5-b61a-4a65-c0d0-a94e4b79160d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "img_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWYDJz0tWnH2"
      },
      "source": [
        "**CNNs in TF Keras**\n",
        "\n",
        "We'll use the Sequential class rely on new layer types that correspond to concepts we covered in lecture: Conv2D, AvgPool2D, MaxPool2D. \n",
        "\n",
        "Details such as kernel size, padding, strides and so on must be specified as args to these classes, where appropriate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9DgLXVCHDt7"
      },
      "source": [
        "model = tfk.Sequential()\n",
        "model.add(tfkl.Conv2D(filters = 1, kernel_size=(3,3), strides=(1,1), \n",
        "                      padding=\"valid\", activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(tfkl.MaxPool2D(pool_size=(4,4)))\n",
        "model.add(tfkl.Flatten())\n",
        "model.add(tfkl.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Af5cnJ9JDvA",
        "outputId": "673fd57c-a870-4160-a0e1-1130d61c04c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 26, 26, 1)         10        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 6, 6, 1)           0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                370       \n",
            "=================================================================\n",
            "Total params: 380\n",
            "Trainable params: 380\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5W4C452HThh"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=tfk.optimizers.RMSprop(),\n",
        "    loss=tfk.losses.CategoricalCrossentropy(),\n",
        ")\n",
        "\n",
        "results = model.fit(ds_train, steps_per_epoch=20, epochs=20, validation_data=ds_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT_6GoNOH1MC"
      },
      "source": [
        "plt.plot(results.history[\"loss\"])\n",
        "plt.plot(results.history[\"val_loss\"])\n",
        "plt.legend(labels=[\"train\", \"val\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s7VuiBmPNuB"
      },
      "source": [
        "plt.stem(model.predict(ds_test.take(1))[9, :])\n",
        "plt.xlabel(\"Digit\")\n",
        "plt.xlabel(\"Probability\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBc0TsgEWcd2"
      },
      "source": [
        "What architectural hyperparameters might we change in the above?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBY6bJSeIPYC"
      },
      "source": [
        "**Exercise - Deep CNN**\n",
        "\n",
        "Build and fit your own CNN model with 3 convolutional **modules**, where each one contains:\n",
        "  * kernel convolution \n",
        "    * you pick number of kernels\n",
        "    * you pick kernel shape/size\n",
        "    * you pick activation\n",
        "  * pooling\n",
        "  * dropout\n",
        "\n",
        "We'll use the Fashion MNIST dataset, a low-res collection of images of clothing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbhcW5QAN2Tz"
      },
      "source": [
        "train, test = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "images, labels = train\n",
        "images = images/255.0\n",
        "images = images[:, :, :, np.newaxis]\n",
        "labels = labels.astype(np.int32)\n",
        "\n",
        "# optional - TF Datasets objects\n",
        "# fmnist_train_ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "# fmnist_train_ds = fmnist_train_ds.shuffle(5000).batch(32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B589FNlTKOR"
      },
      "source": [
        "plt.imshow(images[3, :, :, :].squeeze())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJK4H78OOWZG"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}